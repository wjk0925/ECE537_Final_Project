{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e6ed306-bb27-46d4-9183-aaf030c74fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert txt ljspeech files to tokens fairseq mt tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bd0c5c0-7d93-4f7c-adb9-115c3ee4df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7ed8bb7-b199-45fe-b9cf-a02c720644a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# characters\n",
    "vocab_size = 200\n",
    "endding = \"_noisy_v1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "986a7e0f-ced7-4b40-9530-3cbf7d0774ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = f\"data/ljspeech_hubert{vocab_size}{endding}\"\n",
    "assert not os.path.isdir(out_dir), print(\"Dir exists\")\n",
    "\n",
    "os.makedirs(out_dir)\n",
    "\n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    unit_wf_path = f\"{out_dir}/{split}.unit\"\n",
    "    char_wf_path = f\"{out_dir}/{split}.char\"\n",
    "    \n",
    "    unit_wf = open(unit_wf_path, \"w\")\n",
    "    char_wf = open(char_wf_path, \"w\")\n",
    "\n",
    "    with open(f\"../datasets/LJSpeech/hubert/{split}{vocab_size}{endding}.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            utter_dict = eval(line.strip(\"\\n\"))\n",
    "            unit = utter_dict[\"hubert\"]\n",
    "            text = utter_dict[\"transcription\"]\n",
    "            char = text.replace(\" \", \"|\")\n",
    "            char = (\" \").join(char)\n",
    "            unit_wf.write(unit+\"\\n\")\n",
    "            char_wf.write(char+\"\\n\")\n",
    "\n",
    "    unit_wf.close()\n",
    "    char_wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a83180f-c6f2-49ed-b109-37da52275c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41d369ab-dfcd-44bf-8335-ee216970d30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check matches with original\n",
    "gt_dict = {}\n",
    "with open(f\"/projects/bbmx/junkaiwu/LJSpeech-1.1/wavs_16khz/hubert_l6_v{vocab_size}.km\", \"r\") as f:\n",
    "    for line in f:\n",
    "        gt_dict[line.split(\"|\")[0]] = {}\n",
    "        gt_dict[line.split(\"|\")[0]][\"unit\"] = line.split(\"|\")[1].strip(\"\\n\")\n",
    "        \n",
    "with open(f\"/projects/bbmx/junkaiwu/LJSpeech-1.1/metadata.csv\", \"r\") as f:\n",
    "    for line in f:\n",
    "        gt_dict[line.split(\"|\")[0]][\"transcription_raw\"] = line.split(\"|\")[1].strip(\"\\n\")\n",
    "        gt_dict[line.split(\"|\")[0]][\"transcription\"] = line.split(\"|\")[2].strip(\"\\n\")\n",
    "        \n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    with open(f\"../datasets/LJSpeech/hubert/{split}{vocab_size}.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            utter_dict = eval(line.strip(\"\\n\"))\n",
    "            assert utter_dict[\"hubert\"] == gt_dict[utter_dict[\"audio\"]][\"unit\"]\n",
    "            assert utter_dict[\"transcription\"] == gt_dict[utter_dict[\"audio\"]][\"transcription\"]\n",
    "            assert utter_dict[\"transcription_raw\"] == gt_dict[utter_dict[\"audio\"]][\"transcription_raw\"]\n",
    "            \n",
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    chars = []\n",
    "    units = []\n",
    "    with open(f\"data/ljspeech_hubert{vocab_size}/{split}.char\", \"r\") as f:\n",
    "        for line in f:\n",
    "            chars.append(line.strip(\"\\n\"))\n",
    "\n",
    "    with open(f\"data/ljspeech_hubert{vocab_size}/{split}.unit\", \"r\") as f:\n",
    "        for line in f:\n",
    "            units.append(line.strip(\"\\n\"))\n",
    "    \n",
    "    with open(f\"../datasets/LJSpeech/hubert/{split}{vocab_size}.txt\", \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            utter_dict = eval(line.strip(\"\\n\"))\n",
    "            assert utter_dict[\"hubert\"] == units[i]\n",
    "            assert utter_dict[\"transcription\"] == chars[i].replace(\" \", \"\").replace(\"|\", \" \"), print(chars[i].replace(\" \", \"\").replace(\"|\", \"\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fda9ed2a-1b06-40c5-942b-d98b5c47f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'9\\x00f\\x00\\x16\\x00\\x9b\\x005\\x00`\\x00`\\x00\\x1e\\x00\\x1e\\x00\\x1e\\x00\\x1e\\x00\\x9b\\x00\\x9b\\x00g\\x00v\\x00v\\x00v\\x00\\x9f\\x00\\x97\\x00\\x0e\\x00\\x0e\\x00\\x0e\\x00-\\x00-\\x00-\\x00)\\x00W\\x00\\x82\\x00\\x89\\x00\\x89\\x00.\\x00.\\x00[\\x00[\\x00s\\x00s\\x00\\x1d\\x00\\x1d\\x00\\x18\\x00W\\x00J\\x00J\\x00L\\x00?\\x00\\'\\x00]\\x00]\\x00(\\x00 \\x00 \\x00 \\x00\\xb4\\x00\\xb4\\x00\\x05\\x007\\x007\\x00\\x17\\x00\\x93\\x00\\x93\\x00\\x11\\x00g\\x00g\\x00v\\x00v\\x00\\x9f\\x00~\\x00\\x1e\\x00\\x16\\x00:\\x00W\\x00\\xb9\\x00\\xb9\\x00\\'\\x00A\\x00A\\x00\\x16\\x00\\x10\\x00\\x10\\x00\\x10\\x00\\x12\\x00\\x12\\x00\\x98\\x00\\x98\\x006\\x006\\x00\\x0e\\x00\\x0c\\x00\\x0c\\x00\\x0c\\x00\\x0c\\x00\\x0c\\x00\\x0c\\x00\\xa6\\x00)\\x000\\x00\\t\\x00\\x17\\x00\\x0f\\x00+\\x00+\\x00+\\x00;\\x00\\xb5\\x00\\t\\x00\\t\\x00H\\x00H\\x00\\xa2\\x00\\xa2\\x00\"\\x00\\x10\\x00\\x10\\x00\\x12\\x00\\x12\\x00\\x12\\x00\\x98\\x00\\x98\\x00=\\x00\\x15\\x00\\x15\\x00\\x15\\x00:\\x00:\\x00\\x05\\x007\\x007\\x00N\\x00N\\x00.\\x00.\\x00\\n'\n"
     ]
    }
   ],
   "source": [
    "with open(f\"data-bin/ljspeech_hubert{vocab_size}/test.char-unit.unit.bin\", \"rb\") as f:\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e457eadd-3e16-4adc-8160-5d9b8ebd690a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LJ023-0139|In the case of Supreme Court justices, that pension is $20,000 a year.|In the case of Supreme Court justices, that pension is twenty thousand dollars a year.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(f\"/projects/bbmx/junkaiwu/LJSpeech-1.1/metadata.csv\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if \"$\" in line:\n",
    "            print(line)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862cb62c-9529-4aed-ae97-a70efbba413d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
