{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "586879f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import basename, join, dirname\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fb0a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43873\n"
     ]
    }
   ],
   "source": [
    "# for not yet split! skip if split exits\n",
    "\n",
    "# FILL!\n",
    "audio_dir = \"/Users/junkaiwu/Desktop/Junkai/uiuc/dataset/DS_10283_3443/VCTK-Corpus-0.92/wav16_silence_trimmed_padded\"\n",
    "all_audios = librosa.util.find_files(audio_dir, recurse=True)\n",
    "print(len(all_audios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb65e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL!\n",
    "test = 2000\n",
    "val = 1000\n",
    "train = len(all_audios) - test - val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4d30348",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_audios.sort()\n",
    "np.random.seed(1888)\n",
    "np.random.shuffle(all_audios)\n",
    "\n",
    "train_audios = all_audios[:train]\n",
    "val_audios = all_audios[train:train + val]\n",
    "test_audios = all_audios[train+val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89b74464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71bc1c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split already exits!\n",
    "\n",
    "# FILL!\n",
    "\n",
    "\"\"\"\n",
    "train_txt = \"VCTK/hubert/train.txt\"\n",
    "val_txt = \"VCTK/hubert/val.txt\"\n",
    "test_txt = \"VCTK/hubert/test.txt\"\n",
    "\n",
    "split_txt = {\"train\": train_txt, \"val\": val_txt, \"test\": test_txt}\n",
    "\n",
    "vocab_size = 200\n",
    "km_path = \"/Users/junkaiwu/Desktop/Junkai/uiuc/dataset/DS_10283_3443/VCTK-Corpus-0.92/wav16_silence_trimmed_padded/hubert_l6_v100.km\"\n",
    "out_dir = \"VCTK/hubert/\"\n",
    "feature_type = \"hubert\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "train_txt = \"LJSpeech/hubert/train200.txt\"\n",
    "val_txt = \"LJSpeech/hubert/val200.txt\"\n",
    "test_txt = \"LJSpeech/hubert/test200.txt\"\n",
    "\n",
    "split_txt = {\"train\": train_txt, \"val\": val_txt, \"test\": test_txt}\n",
    "\n",
    "vocab_size = 500\n",
    "km_path = \"/Users/junkaiwu/Desktop/Junkai/uiuc/Speech/hubert_l6_v500.km\"\n",
    "out_dir = \"LJSpeech/hubert\"\n",
    "feature_type = \"hubert\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6e1f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2unit = {}\n",
    "with open(km_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        audio2unit[line.split(\"|\")[0]] = line.split(\"|\")[1].strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dddbdf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    w_f = open(f\"{out_dir}/{split}{vocab_size}.txt\", \"w\")\n",
    "    \n",
    "    with open(split_txt[split], \"r\") as f:\n",
    "        for line in f:\n",
    "            ud = eval(line.strip(\"\\n\"))\n",
    "            ud[feature_type] = audio2unit[ud[\"audio\"]]\n",
    "            w_f.write(str(ud) + \"\\n\")\n",
    "    w_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c4f153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also make for speech resynthesis\n",
    "\n",
    "# FILL!\n",
    "\"\"\"\n",
    "pre = \"data/VCTK/wav16_silence_trimmed_padded/\"\n",
    "post = \".flac\"\n",
    "sr_out_dir = \"../../speech-resynthesis/datasets/VCTK/hubert\"\n",
    "os.makedirs(sr_out_dir, exist_ok=True)\n",
    "\"\"\"\n",
    "\n",
    "pre = \"data/LJSpeech-1.1/wavs_16khz/\"\n",
    "post = \".wav\"\n",
    "sr_out_dir = \"../../speech-resynthesis/datasets/LJSpeech/hubert\"\n",
    "os.makedirs(sr_out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c07ea866",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    \n",
    "    w_f = open(f\"{sr_out_dir}/{split}{vocab_size}.txt\", \"w\")\n",
    "\n",
    "    with open(f\"{out_dir}/{split}{vocab_size}.txt\", \"r\") as f:\n",
    "        for line in f:\n",
    "            ud = eval(line.strip(\"\\n\"))\n",
    "            ud[\"audio\"] = pre + ud[\"audio\"] + post\n",
    "            w_f.write(str(ud) + \"\\n\")\n",
    "            \n",
    "    w_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676d25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AudioLab",
   "language": "python",
   "name": "audiolab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
